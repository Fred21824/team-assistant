# Team Assistant 配置文件示例
# 复制此文件为 config.yaml 并填入实际配置

Server:
  Port: 8090
  Mode: debug

# 数据库配置
MySQL:
  Host: "127.0.0.1:3306"
  User: "root"
  Password: "your_password"
  Database: "team_assistant"

# Redis 配置
Redis:
  Host: "127.0.0.1:6379"
  Password: ""
  DB: 0

# 飞书配置
Lark:
  # 国际版用 larksuite.com，国内版用 feishu.cn
  Domain: "https://open.feishu.cn"
  AppID: "your_app_id"
  AppSecret: "your_app_secret"
  # 事件订阅的验证 Token（在飞书开放平台配置后填入）
  VerificationToken: ""
  # 事件加密 Key（可选，开启加密后填入）
  EncryptKey: ""
  # 机器人的 open_id（用于判断是否@机器人，启动后通过API获取）
  BotOpenID: ""

# GitHub 配置
GitHub:
  # Personal Access Token
  Token: "ghp_your_github_token"
  # Webhook Secret（可选，用于验证 GitHub 推送）
  WebhookSecret: ""
  # 监控的组织/用户
  Organizations:
    - "your-org"

# LLM 配置
LLM:
  # 主模型（NVIDIA NIM + Llama 3.3）
  Provider: "openai"
  APIKey: "nvapi-your-nvidia-api-key"
  Endpoint: "https://integrate.api.nvidia.com/v1/chat/completions"
  Model: "meta/llama-3.3-70b-instruct"

  # 视觉模型配置（可选，用于处理图片消息）
  VisionModel: "meta/llama-3.2-90b-vision-instruct"
  # VisionEndpoint: ""  # 可选，默认使用主 Endpoint
  # VisionAPIKey: ""  # 可选，默认使用主 APIKey

  # 备选模型（智能切换：主模型失败时自动尝试备选模型）
  # 按优先级排列，系统会依次尝试直到成功
  FallbackModels:
    # 备选 1: DeepSeek R1（NVIDIA NIM 托管）
    - Provider: "openai"
      Endpoint: "https://integrate.api.nvidia.com/v1/chat/completions"
      Model: "deepseek-ai/deepseek-r1"
      # APIKey: ""  # 为空则使用主 APIKey

    # 备选 2: Groq（免费快速，作为最后保底）
    - Provider: "groq"
      Endpoint: "https://api.groq.com/openai/v1/chat/completions"
      Model: "llama-3.3-70b-versatile"
      APIKey: "gsk_your_groq_api_key"

  # 其他可用主模型：
  # - NVIDIA NIM: minimaxai/minimax-m2.1, deepseek-ai/deepseek-v3.2
  # - Groq: llama-3.3-70b-versatile（免费）
  # - OpenAI: gpt-4o-mini
  # - Claude (需代理): claude-sonnet-4-20250514

# Dify 配置（可选，启用后使用 Dify 处理对话）
Dify:
  Enabled: false
  BaseURL: "http://localhost/v1"
  APIKey: ""
  DatasetID: ""
